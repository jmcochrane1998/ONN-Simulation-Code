# -*- coding: utf-8 -*-
"""Convolutional Network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/150ckuzJ4BcmZUuv9Sai6pM2RDq94fvzo

**Imports**
"""

from google.colab import drive
drive.mount('/content/drive')
from PIL import Image
import numpy as np
from matplotlib import pyplot as plt
import torch
#print(torch.__version__)
import torchvision
#print(torchvision.__version__)
import torch.nn as nn
from tqdm import tqdm 
from tqdm import trange 
from scipy.io import loadmat
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from matplotlib import cm
from numpy import asarray
import random
from time import time
from scipy import interpolate
from torchvision.datasets import MNIST
from torchvision.datasets.mnist import read_image_file,read_label_file
from torchvision.datasets.utils import extract_archive
from typing import Optional,Callable
import os

"""**Define Global Variables**"""

batchsize= 50  #for training, testing and propagation of error
global_stride=1
Conv_L1_channels= 32 #10
Conv_L2_channels=64
Conv_weight1_height=3 #2
Conv_weight1_width=3 #2
Conv_weight2_height=Conv_weight1_height
Conv_weight2_width=Conv_weight1_width
FC_intermed_size=20
inp_img_size=56*2   # ***ASSUMES A SQUARE IMAGE


# if draw_errors=True, error elements are sampled from the difference distribution. Otherwise, no error elements are sampled and standard MAC operations are implemented. 
draw_errors= True

"""**Define Low Level Functions for Convolution, Difference Distribution Draws, Padding, Matrix Multiplication, and matrix processing**"""

def Pad_4D(inp, w_0, w_1, s):
  '''
  NOTE1: wgt_channels is determined by inp.shape[1]=number of input channels 
  NOTE2: THIS FUNCTIONS DOES AUTOMATIC PADDING BASED ON THE INPUT SIZE, KERNEL SIZE, AND STRIDE
  IT RETURNS A TENSOR (and not an ndarray)
  inp: input 4D *ARRAY*
  [wgt_stacks, wgt_channels, w_0, w_1]: 4D kernel shape with which inp will be convolved
  s: number of stride
  OUTPUTS A 4D (auto-padded) TENSOR
  '''
#  print("inp height"+str(w_0))
#  print("inp width"+str(w_1))
#**OPTIONAL DEBUGGING**
#####################################################
  if (inp.shape[2]-w_0)/s-int((inp.shape[2]-w_0)/s)!=0:
    print('requires padding on dim0')
  if (inp.shape[3]-w_1)/s-int((inp.shape[3]-w_1)/s)!=0:
    print('requires padding on dim1')
#####################################################
  u=0
  L_fill=0
  while w_0+u*s<inp.shape[2]:
    L_fill=w_0+u*s
    u=u+1
  Lgth=L_fill+s
  exc1=Lgth-inp.shape[2]
  if exc1<0:
    exc1=exc1+s
  u2=0
  L_fill2=0
  while w_1+u2*s<inp.shape[3]:
    L_fill2=w_1+u2*s
    u2=u2+1
  Lgth2=L_fill2+s
  exc2=Lgth2-inp.shape[3]
  if exc2 <0:
    exc2=exc2+s
# ***GENERATE INPUT BASED ON WHETHER OR NOT MANUAL PADDING IS USED...***...
# IF MANUAL PADDING IS REQUIRED, THEN THE INPUT (input_gt), will be padded and p_0=p_1=0 (which will later be used from validation)
  pad_top=exc1//2
  pad_bottom=exc1-pad_top
  pad_left=exc2//2
  pad_right=exc2-pad_left
#  if pad_left>pad_right or pad_top>pad_bottom:
#    raise Exception('error: [dim0, dim1] padding is incorrect in its re-distribution')
  manl_pad0_1=nn.ConstantPad2d((pad_left,pad_right,pad_top,pad_bottom), 0)  
  input_test=manl_pad0_1(torch.from_numpy(inp))     
  if exc1<0 or exc2<0:
    print("excess in dim0:"+" "+str(exc1))
    print("excess in dim1:"+" "+str(exc2))
    raise Exception("ERROR: excess in dims 0 or 1 must be positive-valued!")
  return input_test, exc1, exc2



def Inverse_CDF_to_sample(given_dist,length_CDF_data):
  '''
  NOTE: THIS FUNCTION IS DISTINCT FROM  randm_3Dmat, WHICH DRAWS AN DIFFERENCE DISTRIBUTION ELEMENTS TO BE ADDED
  TO THE HADAMARD PRODUCTS IN THE NETWORK. THE ELEMENTS SAMPLED FROM to_plot_storage USING THIS FUNCTION WILL FORM
  THE 3D ERROR VOLUME THAT randm_3Dmat WILL SAMPLE FROM.
  '''
  if draw_errors==True:
    sorted_data=np.sort(given_dist)
# map each sorted data point to a (uniform) index between 0 and 1
    uniform_indx=np.linspace(0,1,len(sorted_data))
    Inv_CDF=interpolate.interp1d(uniform_indx, sorted_data, kind='nearest')
  else:
    Inv_CDF=given_dist
  return Inv_CDF


def draw_3D_matrix_from_3D_diffdist(Diff_volume,k,m,n):
  start_indx0=np.random.randint(0,Diff_volume.shape[0]-k+1)
  start_indx1=np.random.randint(0,Diff_volume.shape[1]-m+1)
  start_indx2=np.random.randint(0,Diff_volume.shape[2]-n+1)
  return np.array(Diff_volume[start_indx0:start_indx0+k,start_indx1:start_indx1+m, start_indx2:start_indx2+n])

def draw_2D_Matrix_from_3D_diffdist(Diff_vol,m,n):
  '''
  diff volume here is 2d
  '''
  #channel_index=np.random.randint(0,Diff_vol.shape[2]+1)
  idx_0=np.random.randint(0,Diff_vol.shape[0]-m+1)
  idx_1=np.random.randint(0,Diff_vol.shape[1]-n+1)
  return np.array(Diff_vol[idx_0:idx_0+m, idx_1:idx_1+n])


def randm_3Dmat(Inverse_CDF,k,m,n):
  '''
  input...
  (k, m,n)=size of random error 3D matrix to be drawn from the given distribution
  output...
  random 3D error matrix of size [k,m,n]
  '''
  if draw_errors==True:
    num_elements_to_extract=k*m*n
    X_unif_to_sample=np.random.uniform(0,1,num_elements_to_extract)
    pdf_samples=Inverse_CDF(X_unif_to_sample)
    Three_D_mat=np.reshape(pdf_samples,(k,m,n))
  else:
    indices_to_sample=np.linspace(1,k*m*n,k*m*n).astype(int)
    indices_to_sample=np.reshape(indices_to_sample,(-1,1))
    sampled_Inverse_CDF=Inverse_CDF[indices_to_sample]
    Three_D_mat=np.reshape(sampled_Inverse_CDF,(k,m,n))
  return Three_D_mat


def quick_split_W3D(matrix):
    '''
    This function splits a weight matrix, W, into two parts: W_+ and W_-, such that W=(W_+)+(W_-). This is done to mitigate
    error accumulation of the network's fully connected layer. Effectively, this offers an alternative to the previous method
    of matrix preprocessing, which accumulated excess error by performing element-wise addition in the weight matrix by its 
    max value to get it in range [0,a]

    INPUT: matrix, a tensor from the state dictionary of the trained model
    '''
    # form the negative of the input matrix
    negative_matrix=-1*matrix
    # use RELU to find the positive matrix W_+
    W_pos=nn.ReLU(inplace=True)(torch.tensor(matrix)).numpy()
    # now, use RELU of the **negative matrix** to find the negative factored matrix W_-
    W_neg=nn.ReLU(inplace=True)(torch.tensor(negative_matrix)).numpy()
    return W_pos, W_neg

def Three_D_Conv_withdiff_Layer2(cdf_inverse,inp,weight,s):
  '''
  NOTE: THIS FUNCTION PERFORMS THE SAME FUNCTIONALITY AS A Conv_2d layer IN PYTORCH BUT INCORPORATES ERROR ELEMENTS FROM THE DIFFERENCE 
  DISTRIBUTION

  The difference distribution elements are drawn from the inverse cdf

  input: 3D padded input array of the form [C,H,W] (padding will be applied prior to Conv_4D)
  weight: 3D weight kernel 

  output: 2d array corresponding to the convolution between the 3D input and the 3D weight kernel
  '''
  Two_d_lst=[]
#  print("input/weight into 3d_conv:")
#  print(inp.shape, weight.shape)
#  print('===========================')
  i_range=(inp.shape[1]-weight.shape[1])/s +1
  j_range=(inp.shape[2]-weight.shape[2])/s +1
##  print(i_range,j_range)
  if 100 * (i_range - int(i_range))!= 0.0:
    print("ERROR")
  if 100 * (j_range - int(j_range))!= 0.0:
    print("ERROR")
##  n_k=np.max(np.abs(inp))
##  if n_k==0:
##    n_k=1
  for i in range(int(i_range)):
      for j in range(int(j_range)):
          X_ijk=inp[:,i*s:i*s+weight.shape[1],j*s:j*s+weight.shape[2]]
          # preprocess input element (X_ijk)
          N_X=np.max(X_ijk)
          if N_X==0:
            N_X=1
          X_ijk_pre=X_ijk/N_X
          # preprocess weight element (weight)
          c=np.min(weight)
          d=np.max(weight)
          N_W=max(np.abs(c),np.abs(d))
          if N_W==0:
            N_W=1
          weight_pre=weight/N_W
          # split the weight into the K_+ and K_- components
          K_plus, K_minus = split_W3D(weight_pre)
          # form the Hadamard products
          prod_plus=X_ijk_pre*K_plus
          prod_minus=X_ijk_pre*K_minus
          # check to ensure that the Hadamard partial products and pre-processed input is in the range [0,1]
  #        if np.min(prod_plus)<0 or np.max(prod_plus)>1:
  #          raise Exception("ERROR: partial product X(ijk)*K_+ not in range [0,1]")
  #        if np.min(prod_minus)<0 or np.max(prod_minus)>1:
  #          raise Exception("ERROR: partial product X(ijk)*K_- not in range [0,1]")
          # *****ADD PERTURBATION (matrix) to the element-to-element products
          prod_plus_with_diff = prod_plus + randm_3Dmat(cdf_inverse,prod_plus.shape[0],prod_plus.shape[1],prod_plus.shape[2])
          prod_minus_with_diff = prod_minus + randm_3Dmat(cdf_inverse,prod_minus.shape[0],prod_minus.shape[1],prod_minus.shape[2])
          # post-process by subtracting: X(ijk)K_+ - X(ijk)K_- and multiplying by the normalization factors
          prod_C_post_processed= N_X*N_W*(prod_plus_with_diff-prod_minus_with_diff)
          prod_C2=np.sum(prod_C_post_processed)       
          Two_d_lst.append(prod_C2)
  Two_d_lst=np.array(Two_d_lst)
  Two_d_lst=np.reshape(Two_d_lst,(int((inp.shape[1]-weight.shape[1])/s +1),int((inp.shape[2]-weight.shape[2])/s +1)))
  return Two_d_lst

def Three_D_Conv_with_volume_error(error_volume,inp,weight,s):
  '''
  NOTE: THIS FUNCTION PERFORMS THE SAME FUNCTIONALITY AS A Conv_2d layer IN PYTORCH BUT INCORPORATES ERROR ELEMENTS FROM THE DIFFERENCE 
  DISTRIBUTION

  The difference distribution elements are drawn from the inverse cdf

  input: 3D padded input array of the form [C,H,W] (padding will be applied prior to Conv_4D)
  weight: 3D weight kernel 

  output: 2d array corresponding to the convolution between the 3D input and the 3D weight kernel
  '''
  Two_d_lst=[]
#  print("input/weight into 3d_conv:")
#  print(inp.shape, weight.shape)
#  print('===========================')
  i_range=(inp.shape[1]-weight.shape[1])/s +1
  j_range=(inp.shape[2]-weight.shape[2])/s +1
##  print(i_range,j_range)
  if 100 * (i_range - int(i_range))!= 0.0:
    print("ERROR")
  if 100 * (j_range - int(j_range))!= 0.0:
    print("ERROR")
##  n_k=np.max(np.abs(inp))
##  if n_k==0:
##    n_k=1
  for i in range(int(i_range)):
      for j in range(int(j_range)):
          X_ijk=inp[:,i*s:i*s+weight.shape[1],j*s:j*s+weight.shape[2]]
          # preprocess input element (X_ijk)
          N_X=np.max(X_ijk)
          if N_X==0:
            N_X=1
          X_ijk_pre=X_ijk/N_X
          # preprocess weight element (weight)
          c=np.min(weight)
          d=np.max(weight)
          N_W=max(np.abs(c),np.abs(d))
          if N_W==0:
            N_W=1
          weight_pre=weight/N_W
          # split the weight into the K_+ and K_- components
          K_plus, K_minus = split_W3D(weight_pre)
          # form the Hadamard products
          prod_plus=X_ijk_pre*K_plus
          prod_minus=X_ijk_pre*K_minus
          # check to ensure that the Hadamard partial products and pre-processed input is in the range [0,1]
          if np.min(prod_plus)<0 or np.max(prod_plus)>1:
            raise Exception("ERROR: partial product X(ijk)*K_+ not in range [0,1]")
          if np.min(prod_minus)<0 or np.max(prod_minus)>1:
            raise Exception("ERROR: partial product X(ijk)*K_- not in range [0,1]")
          # *****ADD PERTURBATION (matrix) to the element-to-element products
          prod_plus_with_diff = prod_plus #+ draw_3D_matrix_from_3D_diffdist(error_volume,prod_plus.shape[0],prod_plus.shape[1],prod_plus.shape[2])  #randm_3Dmat(cdf_inverse,prod_plus.shape[0],prod_plus.shape[1],prod_plus.shape[2])
          prod_minus_with_diff = prod_minus #+draw_3D_matrix_from_3D_diffdist(error_volume,prod_minus.shape[0],prod_minus.shape[1],prod_minus.shape[2]) #randm_3Dmat(cdf_inverse,prod_minus.shape[0],prod_minus.shape[1],prod_minus.shape[2])
          # post-process by subtracting: X(ijk)K_+ - X(ijk)K_- and multiplying by the normalization factors
          prod_C_post_processed= N_X*N_W*(prod_plus_with_diff-prod_minus_with_diff)
          prod_C2=np.sum(prod_C_post_processed)       
          Two_d_lst.append(prod_C2)
  Two_d_lst=np.array(Two_d_lst)
  Two_d_lst=np.reshape(Two_d_lst,(int((inp.shape[1]-weight.shape[1])/s +1),int((inp.shape[2]-weight.shape[2])/s +1)))
  return Two_d_lst


def Conv_4D_With_Processing_Layer2(cdf_inverse,x,w,s):
  '''
  This function uses Three_D_Conv and preprocess_mat to compute a single convolution between a 4D input NUMPY ARRAY
  and a 4D weight NUMPY ARRAY. It returns the 4D convolved NUMPY ARRAY.
  INPUTS...
  x: 4D input (numpy array) **PADDED**!
  w: 4D weight (numpy array)
  s: stride
  '''
  Four_d_stack_lst=[]
  for img_indx in trange(x.shape[0]):
    image=x[img_indx]  # 3D IMAGE 
    Three_d_stack_lst=[]
    for kernel_indx in range(w.shape[0]):
      kernel=w[kernel_indx]
      shape0=int((image.shape[1]-kernel.shape[1])/s +1)
      shape1=int((image.shape[2]-kernel.shape[2])/s +1)
      kernel=w[kernel_indx] # 3D KERNEL
#      print(kernel.shape)
      # (1) pre-process input image
#      n_img=np.max(image)
#      image_pre=image/n_img
#      # (2) pre-process weight
#      c=np.min(kernel)
#      d=np.max(kernel)
#      n_kernel=max(np.abs(c),np.abs(d))
#      kernel_pre=kernel/n_kernel
#      # (3) Split K_pre=K_+|[0,1] - K_-|[0,1] 
#      k_plus,k_minus=split_W3D(kernel)
#      # (4) compute the convolutions with K_+ and K_- seperately 
#      Conv_plus=Three_D_Conv_withdiff_Layer2(image,k_plus,s)
#      Conv_minus=Three_D_Conv_withdiff_Layer2(image,k_minus,s)
      # (5) Combine: Conv(K)+Conv(K_+)-Conv(K_-) and post-process by multiplying by the normalization factors
#      Post_Processed=n_img*n_kernel*(Conv_plus-Conv_minus)
      Conv3D=Three_D_Conv_withdiff_Layer2(cdf_inverse,image,kernel,s)
      Three_d_stack_lst.append(Conv3D)
    Three_d_stack=np.reshape(Three_d_stack_lst,(w.shape[0],shape0,shape1))
    Four_d_stack_lst.append(Three_d_stack)
  Post_Processed_Res=np.reshape(Four_d_stack_lst,(x.shape[0],w.shape[0],shape0,shape1)) 
  return Post_Processed_Res


def Conv4d_with_3d_diff_dist(error_volume,x,w,s):
  Four_d_stack_lst=[]
  for img_indx in trange(x.shape[0]):
    image=x[img_indx]  # 3D IMAGE 
    Three_d_stack_lst=[]
    for kernel_indx in range(w.shape[0]):
      kernel=w[kernel_indx]
      shape0=int((image.shape[1]-kernel.shape[1])/s +1)
      shape1=int((image.shape[2]-kernel.shape[2])/s +1)
      kernel=w[kernel_indx] # 3D KERNEL
      Conv3D=Three_D_Conv_with_volume_error(error_volume,image,kernel,s)  #Three_D_Conv_withdiff_Layer2(cdf_inverse,image,kernel,s)
      Three_d_stack_lst.append(Conv3D)
    Three_d_stack=np.reshape(Three_d_stack_lst,(w.shape[0],shape0,shape1))
    Four_d_stack_lst.append(Three_d_stack)
  Post_Processed_Res=np.reshape(Four_d_stack_lst,(x.shape[0],w.shape[0],shape0,shape1)) 
  return Post_Processed_Res



def split_W2D(matrix):
    '''
    This function splits a weight matrix, W, into two parts: W_+ and W_-, such that W=(W_+)+(W_-). This is done to mitigate
    error accumulation of the network's fully connected layer. Effectively, this offers an alternative to the previous method
    of matrix preprocessing, which accumulated excess error by performing element-wise addition in the weight matrix by its 
    max value to get it in range [0,a]
    '''
    W_pos_lst=[]
    W_neg_lst=[]
    for i in range(matrix.shape[0]):
      for j in range(matrix.shape[1]):
        if matrix[i,j]>=0:
          W_pos_lst.append(matrix[i,j])
          W_neg_lst.append(0)           
        elif matrix[i,j]<0:
          W_neg_lst.append(np.abs(matrix[i,j]))
          W_pos_lst.append(0)
    W_pos=np.array(W_pos_lst)
    W_neg=np.array(W_neg_lst) 
    W_pos=np.reshape(W_pos,(matrix.shape[0],matrix.shape[1]))
    W_neg=np.reshape(W_neg,(matrix.shape[0],matrix.shape[1]))
    return torch.tensor(W_pos), torch.tensor(W_neg)

def randm_mat(CDF_Inverse,m,n):
  '''
  input...
  (m,n)=size of random error matrix to be drawn from the difference distribution, to_plot
  output...
  random error matrix of size [m,n]
  '''
  if draw_errors==True:
  #sorted_data=np.sort(given_dist)
    n_extracted=m*n
  #uniform_indx=np.linspace(0,1,len(sorted_data))
  #Inv_CDF=interpolate.interp1d(uniform_indx, sorted_data, kind='nearest')
    X_unif_to_sample=np.random.uniform(0,1,n_extracted)
    pdf_samples=CDF_Inverse(X_unif_to_sample)
    rand_mat=np.array(pdf_samples)
    rand_mat=np.reshape(rand_mat, (m,n))
  else:
    indices_to_sample=np.linspace(1,m*n,m*n).astype(int)
    indices_to_sample=np.reshape(indices_to_sample,(-1,1))
    sampled_Inverse_CDF=CDF_Inverse[indices_to_sample]
    rand_mat=np.reshape(sampled_Inverse_CDF,(m,n))
  return rand_mat


def Matrix_Multiply_with_diff_dist(inverse_of_cdf,X,W):
  '''
  performs a simulated matrix product between two 2d tensors
  X: 2d input tensor of size [Batch_number, N]
  W: 2d weight tensor of size [M,N]
  **NOTE**: THIS ASSUMES THAT X AND W ARE BOTH PREPROCESSED TO BE IN THE RANGE [0,1]
  '''
  #X=X.numpy()
  #W=W.numpy()

  X_lst=[]
# loop through rows of the input to form the 3D input tensor
  for row_indx in range(X.shape[0]):
    row_to_copy=X[row_indx]
    matrix_from_row=np.tile(row_to_copy,(W.shape[0],1))
    X_lst.append(matrix_from_row)

  X_vstacked=np.vstack(X_lst)

  stacked_weight_matrices=[]
  for matrix_indx in range(X.shape[0]):
    weight_matrix_to_stack=W
    stacked_weight_matrices.append(weight_matrix_to_stack)
 
  W_vstacked=np.vstack(stacked_weight_matrices)
  # FORM THE HADAMARD PRODUCT 
  Hadamard_prod=W_vstacked*X_vstacked
  # ADD MATRIX OF ERRORS TO HADAMARD PRODUCT

  print(np.max(randm_mat(inverse_of_cdf, Hadamard_prod.shape[0], Hadamard_prod.shape[1])))

  Hadamard_prod_with_errors=Hadamard_prod + randm_mat(inverse_of_cdf, Hadamard_prod.shape[0], Hadamard_prod.shape[1])
  # SUM HADAMARD PRODUCT TO FORM MATRIX PRODUCT
  summed_Hadamard_prod=np.sum(Hadamard_prod_with_errors, axis=1)
  matrix_prod=np.reshape(summed_Hadamard_prod,(X.shape[0],W.shape[0]))
  return torch.tensor(matrix_prod)


def Matmul_with_2d_diffdist_elements(error_surface,X,W):
  '''
  performs a simulated matrix product between two 2d tensors
  X: 2d input tensor of size [Batch_number, N]
  W: 2d weight tensor of size [M,N]
  **NOTE**: THIS ASSUMES THAT X AND W ARE BOTH PREPROCESSED TO BE IN THE RANGE [0,1]
  '''
  #X=X.numpy()
  #W=W.numpy()

  X_lst=[]
# loop through rows of the input to form the 3D input tensor
  for row_indx in range(X.shape[0]):
    row_to_copy=X[row_indx]
    matrix_from_row=np.tile(row_to_copy,(W.shape[0],1))
    X_lst.append(matrix_from_row)

  X_vstacked=np.vstack(X_lst)

  stacked_weight_matrices=[]
  for matrix_indx in range(X.shape[0]):
    weight_matrix_to_stack=W
    stacked_weight_matrices.append(weight_matrix_to_stack)
 
  W_vstacked=np.vstack(stacked_weight_matrices)
  # FORM THE HADAMARD PRODUCT 
  Hadamard_prod=W_vstacked*X_vstacked
  if np.min(Hadamard_prod)<0 or np.max(Hadamard_prod)>1:
    print([np.min(Hadamard_prod),np.max(Hadamard_prod)>1])
    print("ERROR: Hadamard product in fully connected layer not in [0,1]")
#  print(".............")
#  print(Hadamard_prod.shape)
#  print(".............")
  # ADD MATRIX OF ERRORS TO HADAMARD PRODUCT
#  print(np.max(draw_2D_Matrix_from_3D_diffdist(error_surface, Hadamard_prod.shape[0], Hadamard_prod.shape[1])))
  Hadamard_prod_with_errors=Hadamard_prod + draw_2D_Matrix_from_3D_diffdist(error_surface, Hadamard_prod.shape[0], Hadamard_prod.shape[1]) ## randm_mat(error_surface, Hadamard_prod.shape[0], Hadamard_prod.shape[1]) #
  # SUM HADAMARD PRODUCT TO FORM MATRIX PRODUCT
  summed_Hadamard_prod=np.sum(Hadamard_prod_with_errors, axis=1)
  matrix_prod=np.reshape(summed_Hadamard_prod,(X.shape[0],W.shape[0]))
  return torch.tensor(matrix_prod)

"""**Define Fast 4d Convolutional Function**"""

def ADV_Conv_4D_With_Processing(cdf_inverse_obj,x,w,s,h_padding,w_padding,d_h,d_w):
  '''
  *****NOTE****: TO DRAW FROM A DISTRIBUTION OF ZEROS, SET cdf_inverse=CONV_Diff_Vol, and use 'draw_3D_matrix_from_3D_diffdist' instead of 'randm_3Dmat'

  This function uses Three_D_Conv and preprocess_mat to compute a single convolution between a 4D input NUMPY ARRAY
  and a 4D weight NUMPY ARRAY. It returns the 4D convolved NUMPY ARRAY.
  INPUTS...
  x: 4D input (numpy array) **PADDED**!
  w: 4D weight (numpy array)
  s: stride
  '''
  #*******************form the dilated weight kernel*****************************#
  dilated_kernel_lst=[]
  for kernel_indx in range(w.shape[0]):
      kernel=w[kernel_indx]
      weight_depth=kernel.shape[0]
      init_kernel_h = kernel.shape[1]
      init_kernel_w = kernel.shape[2]
      # form the dimension of the dilated kernel
      dil_kernel_h = init_kernel_h + (init_kernel_h-1)*(d_h-1)
      dil_kernel_w = init_kernel_w + (init_kernel_w-1)*(d_w-1)
      # form a blank 3D dilated kernel to be filled in at the appropriate indices
      dilated_kernel = np.zeros((weight_depth, dil_kernel_h, dil_kernel_w)) # **to be filled in...
      # generate index map from the initial (non-dilated) kernel to the final (dilated) kernel...
      h_range=list(range(0,init_kernel_h))
      w_range=list(range(0,init_kernel_w))
      init_indx_pairs=np.array(np.meshgrid(h_range,w_range)).T.reshape(-1, 2) 
      for (a,b) in init_indx_pairs:
        a_dil=a*d_h
        b_dil=b*d_w
        dilated_kernel[:,a_dil,b_dil]=kernel[:,a,b]
      # over-write the kernel in all following lines of code to be the dilated kernel
      #kernel=dilated_kernel
      dilated_kernel_lst.append(dilated_kernel)
  Four_d_dilated_kernel=np.stack(dilated_kernel_lst,axis=0)
  ################################################################################
  # set the weight kernel, w, to equal the dilated kernel for all future computation
  w=Four_d_dilated_kernel
  Four_d_stack_lst=[]
  # loop through each 3D image  
  stacked_4d_image_lst=[]
  num_times_to_copy_x=w.shape[0]
  num_time_to_copy_w=x.shape[0]
  total_num_stacked_inputs=num_times_to_copy_x*num_time_to_copy_w
  for img_indx in range(x.shape[0]):
    image=x[img_indx]  # 3D IMAGE 
    # pad 3D image
    image=nn.ConstantPad2d((w_padding, w_padding, h_padding, h_padding),0)(torch.tensor(image)).numpy()
    # copy/stack (in the height dimension)
    stacked_image=np.tile(image,(num_times_to_copy_x,1))
    stacked_4d_image_lst.append(stacked_image)
    #
  stacked_4d_image=np.hstack(stacked_4d_image_lst)
  # copy/stack filter with the appropriate paddings inserted 
  Top_padding=image.shape[1]-w.shape[2]
  padding_function=nn.ConstantPad2d((0,0,Top_padding,0), 0)
  padd_function_bottom=nn.ConstantPad2d((0,0,0,Top_padding), 0) 
  stacked_weight_lst=[]
  nth_stacked_weight_lst=[]
  #############################################################################################################
  list_of_indices_to_del=[]
  first_list_of_indices_to_delete=[]
  first_index_to_delete=int(w.shape[2])
  first_list_of_indices_to_delete.append(first_index_to_delete)
  for c in range(Top_padding-1):
    first_index_to_delete+=1
    first_list_of_indices_to_delete.append(int(first_index_to_delete))
  list_of_indices_to_del.append(first_list_of_indices_to_delete)
  for d in range(total_num_stacked_inputs-2):
  # if we have 'n' stacked inputs, then we have 'n-1' zero fillers in between, and we already have the index list for one of them, so we repeat the below proceedure n-1-1=n-2 times
    lst_to_append=list(np.array(first_list_of_indices_to_delete)+w.shape[2]+Top_padding)
    list_of_indices_to_del.append(lst_to_append)
    first_list_of_indices_to_delete=lst_to_append
  list_of_indices_to_del=list(np.array(list_of_indices_to_del).flatten())
  ################################################################################################################
  for k in range(w.shape[0]):
    if k==0:
      stacked_weight_lst.append(w[0]) 
      nth_stacked_weight_lst.append(w[0])
    else:
      padded_weight=padding_function(torch.tensor(w[k])).numpy()
      stacked_weight_lst.append(padded_weight)
      nth_stacked_weight_lst.append(padded_weight)
      # no bottom padding
      nth_padded=padding_function(torch.tensor(w[k])).numpy()
      nth_stacked_weight_lst.append(nth_padded)
  stacked_4d_filter=np.hstack(stacked_weight_lst)
  stacked_4d_filter=padd_function_bottom(torch.tensor( stacked_4d_filter)).numpy()
  nth_padded_bank=np.hstack(nth_stacked_weight_lst)
  tiled_filter_bank=np.tile(stacked_4d_filter,(num_time_to_copy_w,1))
  num_padded_rows=Top_padding
  k_0=tiled_filter_bank.shape[1]-1
  indices_to_del=[k_0]
  for a in range(num_padded_rows-1):
    indices_to_del.append(k_0-1)
    k_0=k_0-1  
  # delete bottom block of zeros in place
  tiled_filter_bank=np.delete(tiled_filter_bank,indices_to_del,1)
###########################################################################
#** form the 3d bernouli mask in the same shape as the tiled filter bank
  bernouli_ones=torch.ones([tiled_filter_bank.shape[0],tiled_filter_bank.shape[1],tiled_filter_bank.shape[2]]).numpy()
# for each index to delete, set that sub-block equalt to zeros
  for index_to_zero in list_of_indices_to_del:
    bernouli_ones[:,index_to_zero]=0
###########################################################################
# the two 3D tensors to be convolved are: stacked_4d_image and tiled_filter_bank
  i_range=(stacked_4d_image.shape[1]-tiled_filter_bank.shape[1])/s +1
  j_range=(stacked_4d_image.shape[2]- tiled_filter_bank.shape[2])/s +1
  lateral_size = tiled_filter_bank.shape[2] 
  stacked_conv_block_lst=[]
  for i in trange(int(i_range)):
      for j in range(int(j_range)):
        # perform the lateral convolutions...
        x_ijk_lateral_conv=stacked_4d_image[:,i*s:i*s+tiled_filter_bank.shape[1],j*s:j*s+tiled_filter_bank.shape[2]]  

        ############################################################################################################################################## 
        # pre-process x_ijk by dividing by it by its maximum value
        n_x = np.max(x_ijk_lateral_conv)  
        if n_x==0:
          n_x=1    
        x_ijk_pre=x_ijk_lateral_conv/n_x
        # pre-process the filter stack 
        c=np.min(tiled_filter_bank) 
        d=np.max(tiled_filter_bank) 
        n_w=max(np.abs(c),np.abs(d))
        if n_w==0:
          n_w=1
        filter_pre=tiled_filter_bank/n_w
        stacked_filter_plus, stacked_filter_minus = quick_split_W3D(filter_pre)
   #     tiled_filter_bank_pre, a, n_w=matrix_preprocess(tiled_filter_bank)
        # perform the + and -Hadamard product
        Hadamard_prod_plus= x_ijk_pre*stacked_filter_plus  #x_ijk_lateral_conv*tiled_filter_bank
        Hadamard_prod_minus= x_ijk_pre*stacked_filter_minus
        #*****ADD MATRIX OF ERRORS HERE... 
        # ****change the code below to draw from either the INV_CDF or a volume of zeros *****
        diff_dist_draw_plus = draw_3D_matrix_from_3D_diffdist(cdf_inverse_obj,Hadamard_prod_plus.shape[0],Hadamard_prod_plus.shape[1],Hadamard_prod_plus.shape[2])   #randm_3Dmat(cdf_inverse,Hadamard_prod.shape[0],Hadamard_prod.shape[1],Hadamard_prod.shape[2])    
        diff_dist_draw_minus = draw_3D_matrix_from_3D_diffdist(cdf_inverse_obj,Hadamard_prod_minus.shape[0],Hadamard_prod_minus.shape[1],Hadamard_prod_minus.shape[2])

        # 
  #      print(np.max(diff_dist_draw_plus)) 
  #      print(np.max(diff_dist_draw_minus))
        # 
        
        Hadamard_with_error_plus = Hadamard_prod_plus + bernouli_ones*diff_dist_draw_plus
        Hadamard_with_error_minus = Hadamard_prod_minus + bernouli_ones*diff_dist_draw_minus
        # post process by multiplying the normalization factors and subtracting: X*W=(n_x)(n_w)(X_pre*W_+ - X_pre*W_-)
        Post_processed_Hadamard_with_error=n_x*n_w*(Hadamard_with_error_plus -  Hadamard_with_error_minus)  #  a*x_ijk_lateral_conv

        ##############################################################################################################################################
        # sum in channel dimension (outputs 2d array)
        Sum_in_channel_dim=np.sum(Post_processed_Hadamard_with_error, axis=0)  #np.sum(Hadamard_with_error,axis=0)
        # delete all zeros from the 2d array
        Three_d_conv_vol_nonzero=np.delete(Sum_in_channel_dim,list_of_indices_to_del,0)
        # reshape 2d array into LxLxD block
        Conv_block_3d=np.reshape(Three_d_conv_vol_nonzero,(-1,lateral_size,lateral_size))
        # now, sum in the lateral dimension. this turns the LxLxD array into a 1-d array
        Sum_in_lateral_dimension=np.sum(np.sum(Conv_block_3d,axis=1),axis=1)
        # reshape the 1d lateral summation into a 1x1xD block
        Three_d_block_to_append=np.reshape(Sum_in_lateral_dimension,(-1,1,1))
        # append to list
        stacked_conv_block_lst.append(Three_d_block_to_append)
  stacked_conv_block=np.hstack(stacked_conv_block_lst)    
  # reshape from [depth,H_temp,1] --> [depth,L,L] where L=sqrt(H)
  square_shape_L=int(np.sqrt(stacked_conv_block.shape[1]))
  lateral_square_conv_block=np.reshape(stacked_conv_block,(stacked_conv_block.shape[0],square_shape_L,square_shape_L))
  # reshape 3d conv block into 4d convblock keeping the lateral dimensions and infering the per-3d-output depths
  num_channels_for_output=x.shape[0]
  four_d_conv_block=np.reshape(lateral_square_conv_block,(num_channels_for_output,-1,lateral_square_conv_block.shape[1],lateral_square_conv_block.shape[2]))
  return four_d_conv_block

"""**Load Training and Testing Data**"""

trans=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Resize([inp_img_size,inp_img_size])])

train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=True, download=True,transform=trans),batch_size=batchsize, shuffle=True)

test_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=False, download=True,transform=trans),batch_size=batchsize, shuffle=False)


training_data=enumerate(train_loader)
testing_data=enumerate(test_loader)

"""**Compute the Number of batches in a single training and testing epoch**"""

counter=0
for train_img, train_gt in train_loader:
  if counter==1:
    print(train_gt)
    print("ground truth...")
    print(train_gt)
  counter+=1

num_batches_train_data=counter
print("there are"+" "+str(num_batches_train_data)+" "+"batches in a single training epoch")

max_test_pixels=[]
tst_c=0
for test_img, test_gt in test_loader:
  max_test_pixels.append(torch.min(test_img))
  tst_c+=1

test_pixels_array=np.array(max_test_pixels)
print("there are"+" "+str(tst_c)+" "+"batches in a single testing epoch")
print("the min pixel value for the test images is"+" "+str(np.min(test_pixels_array)))

"""**Show Sample Images**"""

_,train_data=next(training_data)
###########################################
# one training batch
sample_train_img_batch=train_data[0]
sample_train_gt_batch=train_data[1]
print("training batch is of size"+" "+str(sample_train_img_batch.size()))
print("training batch gt is of size"+" "+str(sample_train_gt_batch.size()))

# one training sample
train_sample=sample_train_img_batch[0]
train_sample_gt=sample_train_gt_batch[0]
print("single training image is of size"+str(train_sample.size()))
print("corresponding gt is"+" "+str(train_sample_gt))
print()
print()
########################################
# one testing batch
_,test_data=next(testing_data)
sample_test_img_batch=test_data[0]
sample_test_gt_batch=test_data[1]
print("testing batch is of size"+" "+str(sample_test_img_batch.size()))
print("testing batch gt is of size"+" "+str(sample_test_gt_batch.size()))

# one testing sample
test_sample=sample_test_img_batch[0]
test_sample_gt=sample_test_gt_batch[0]
print("single test image is of size"+" "+str(test_sample.size()))
print("corresponding gt is"+" "+str(test_sample_gt))
print()
print()
print("some sample images are shown below")
plt.figure(figsize=(6,6))
plt.imshow(train_sample.squeeze())
plt.title("sample training image")

plt.figure(figsize=(6,6))
plt.imshow(test_sample.squeeze())
plt.title("sample test image")

"""**Build a Convnet structure and run a sample forward pass in order to determine the size of the image right before it enters the linear part of the network. This size will be used to set the linear network parameters**

**Use an identity convolution to down-sample**
"""

x=sample_train_img_batch
w=torch.ones([1,1,2,2])
###########################################################################################################################
Downsampling_Convolution=nn.Conv2d(x.shape[1],w.shape[0],kernel_size=(w.shape[2],w.shape[3]),padding=0,stride=2,bias=False)
with torch.no_grad():
  Downsampling_Convolution.weight=torch.nn.Parameter(w)
############################################################################################################################
downsampled_x=Downsampling_Convolution(x)
print("down-sampled image size:"+" "+str(downsampled_x.size()))

#***WE DON'T UPSAMPLE IN THIS CASE SINCE WE ARE JUST MAPPING IMAGES TO CLASSES

image=sample_train_img_batch


### first convolutional layer 
C_layer1=nn.Conv2d(1, Conv_L1_channels, kernel_size=[Conv_weight1_height,Conv_weight1_width], stride=global_stride, padding=1, bias=False)
### second convolutional layer
C_layer2=nn.Conv2d(Conv_L1_channels, Conv_L2_channels, kernel_size=[Conv_weight2_height,Conv_weight2_width], stride=global_stride, padding=1, bias=False)
# put into through layer1 (no need to RELU since activation functions don't alter the tensor size)

x_d=Downsampling_Convolution(image)
x1=C_layer1(x_d)
# pad
#x2=Pad_4D(x1.detach().numpy(),Conv_weight2_height,Conv_weight2_width, global_stride)[0]
# put through layer2 (again, no need to RELU)
x3=C_layer2(x1)
# no need to implement drop out since it doesn't change the tensor size

Height_before_FC=x3.size()[2]
Width_before_FC=x3.size()[3]
print(Height_before_FC)
print(Width_before_FC)

"""**From the computed height and width before the fully connected layer, build the ConvNet**"""

class ConvNet(nn.Module):
  def __init__(self):
    super(ConvNet, self).__init__()
    self.conv_layer1=nn.Sequential(nn.Conv2d(1, Conv_L1_channels, kernel_size=[Conv_weight1_height,Conv_weight1_width], stride=global_stride, padding=1, bias=False), nn.ReLU(inplace=True))#, nn.MaxPool2d(kernel_size=2, stride=2))
    self.conv_layer2=nn.Sequential(nn.Conv2d(Conv_L1_channels, Conv_L2_channels, kernel_size=[Conv_weight2_height,Conv_weight2_width], stride=global_stride, padding=1, bias=False), nn.ReLU(inplace=True))#, nn.MaxPool2d(kernel_size=2, stride=2))
    self.drop_layer=nn.Dropout()
    # no change in dimension from drop out
    # flatten into (flattened lateral size of input)*(number of channels), where the network operates on a single image within an image batch.
    # note that the linear module performs: x@W.T 
    #self.fc_layer1=nn.Linear(7*7*64,1000, bias=False)
    self.fc_layer1=nn.Sequential(nn.Linear(int(Height_before_FC*Width_before_FC*Conv_L2_channels),FC_intermed_size, bias=False),nn.ReLU(inplace=True))
    self.fc_layer2=nn.Linear(FC_intermed_size,10, bias=False)
  def forward(self,x):
    out1=self.conv_layer1(x)
#    print('============')
#    print(out1.size())
#    print('============')
    out2=self.conv_layer2(out1)
#    print('============')
#    print(out2.size())
#    print('============')
    out3=self.drop_layer(out2)
    out3_flat=out3.view(batchsize,int(out2.size()[1]*out2.size()[2]*out2.size()[3]))
#    print('============')
#    print(out3_flat.size())
#    print('============')
    out4=self.fc_layer1(out3_flat)
    out5=self.fc_layer2(out4)
    OUT=nn.Softmax()(out5)
    return OUT

"""**Run a sample input through the ConvNet to Verify Functionality**"""

net=ConvNet()
downsampled_input_image_batch=Downsampling_Convolution(sample_train_img_batch)
out=net(downsampled_input_image_batch)
sample_out=torch.argmax(out, dim=1)
print("sample output is"+" "+str(sample_out))

"""**Train ConvNet**"""

def train_model(epochs, model, loss_fn, optimizer):
  loss_batch=[]
  for epoch in trange(epochs):
    epoch_acc=[]
    # per epoch loss
    train_loss = 0
    for input,labels in train_loader:
#      print("original input size was"+str(input.size()))
#      print("with stride..."+str(global_stride))
#      input=Pad_4D(input.numpy(), Conv_weight1_height, Conv_weight1_width, global_stride)[0]
#      print("after automatic padding, resulting size is"+str(input.size()))
    # downsample resolution from 112 to 56
      w=torch.ones([1,1,2,2])
      Downsampling_Convolution=nn.Conv2d(input.size()[1],w.size()[0],kernel_size=(w.size()[2],w.size()[2]),padding=0,stride=2,bias=False)
      with torch.no_grad():
         Downsampling_Convolution.weight=torch.nn.Parameter(w)
      downsampled_x=Downsampling_Convolution(input)
#      print("downsampled shape:"+" "+str(downsampled_x.size()))
    # run forward pass
      output=model(downsampled_x)[0]
      print("======")
      print(output.shape)
      print(labels.shape)
      #print(output.size())
      print("=======")
      # REMEMBER THAT WE DON'T NEED TO UPSAMPLE IN THIS CASE
      #print(downsampled_output.size())
  # compute loss
      print(labels)
      loss=loss_fn(output,labels)
      train_loss+=loss
      loss_batch.append(loss)
  # zero all gradients from previous epochs/iterations
      optimizer.zero_grad()
  # differentiate loss with respect to all model parameters and set = 0
      loss.backward()
  # take a step in parameter space anti-parallel to the computed gradient (theta --> theta-(learning rate)*gradient of error w.r.t theta)
      optimizer.step()
  # track accuracy 
      predictions=torch.argmax(output,dim=1)
      predictions=list(predictions)
      for j in range(len(predictions)):
        out_pred=predictions[j]
        target_pred=labels[j]
        if out_pred==target_pred:
          epoch_acc.append(1)
    print('--------------------------------------------------------------')
    print("EPOCH:"+str(epoch))
    print("Training accuracy for epoch"+" "+str(epoch)+" "+"is"+" "+str(len(epoch_acc)/(len(predictions)*num_batches_train_data)))
    print("Average training Loss (loss per number of batches) for epoch"+" "+str(epoch)+" "+"is"+" "+str(train_loss/num_batches_train_data))
    print('--------------------------------------------------------------')
  return model, loss_batch

#epochs=10
#model=ConvNet()
#loss_fn=nn.CrossEntropyLoss()
#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
#training_res=train_model(epochs, model, loss_fn, optimizer)

#trained_model=training_res[0]
#training_losses=training_res[1]

#plt.figure(figsize=(6,6))
#plt.plot(training_losses)#
#plt.xlabel("Training Time (in batches)")
#plt.ylabel("Training Loss")
#plt.title("Training Plot for 2 Layer Convolutional Model")

###PATH='/content/drive/My Drive/Convolutional_2LayerMNIST_batchsize50_resolution28_epochs10.pt'
##PATH='/content/drive/My Drive/Convolutional_2LayerMNIST_batchsize50_resolution56_epochs10.pt'
#PATH='/content/drive/My Drive/Convolutional_2LayerMNIST_batchsize50_resolution112_epochs10_INTERMEDIATE_OUTPUTS_SHOWN.pt'
#torch.save(trained_model, PATH)

"""**Load and Test Trained ConvNet**"""

testing_batches=1

##FILE_PATH='/content/drive/My Drive/Convolutional_2LayerMNIST_batchsize50_resolution28_epochs10.pt'
#FILE_PATH='/content/drive/My Drive/Convolutional_2LayerMNIST_batchsize50_resolution56_epochs10.pt'
FILE_PATH='/content/drive/My Drive/Convolutional_2LayerMNIST_batchsize50_resolution112_epochs10.pt'
ConvNet=torch.load(FILE_PATH)
ConvNet.eval()

def test_CONV_model(model):
  '''
  tests a convolutional model
  INPUT: a model of the form y=f(x) that maps an input to an output
  '''
  output_lst=[]
  gt_lst=[]
  test_counter=0
  acc_per_batch=[]
  for test_batch,test_gt in test_loader:
 #   print(test_batch.size())
    print("batch number"+" "+str(test_counter)+" "+"of"+" "+str(testing_batches))
    test_counter +=1
    if test_counter>testing_batches:
        break
    with torch.no_grad():
      w=torch.ones([1,1,2,2])
      Downsampling_Convolution=nn.Conv2d(test_batch.size()[1],w.size()[0],kernel_size=(w.size()[2],w.size()[2]),padding=0,stride=2,bias=False)
      with torch.no_grad():
         Downsampling_Convolution.weight=torch.nn.Parameter(w)
        # downsample input
      downsampled_input= Downsampling_Convolution(test_batch)
      # forward pass
      output=model(downsampled_input)
      print(output.shape)
      # class predictions
      final_out=torch.argmax(output,dim=1).numpy()  
      print(final_out)
      output_lst.append(final_out)
      gt=test_gt.numpy()
      gt_lst.append(gt)
      # first, look at the per-batch accuracy level
      current_acc=[]
      for k in range(len(final_out)):
        if final_out[k]==gt[k]: 
          current_acc.append(1)
      batch_accuracy=len(current_acc)/len(final_out)
      acc_per_batch.append(batch_accuracy)

 # next, horizontally stack the outputs and ground truths into single arrays
  output_array=np.hstack(output_lst)
  gt_array=np.hstack(gt_lst)
  # compare the stacked output array with the stacked ground truth array
  correct_predictions=[]
  for i in range(len(output_array)):
    output_elem=output_array[i]
    gt_elem=gt_array[i]
    if output_elem==gt_elem:
      correct_predictions.append(1)
  
  accuracy=len(correct_predictions)/len(output_array)
  return accuracy, acc_per_batch




print()
tst=test_CONV_model(ConvNet)
print("accuracy of ground truth model is"+" "+str(tst[0]))
print("the list of per-batch accuracies is:"+" "+str(tst[1]))

"""**Print Model State Dictionary**"""

Kernel_list=[]
for param_tensor in ConvNet.state_dict():
  print(param_tensor, ConvNet.state_dict()[param_tensor].size())
  Kernel_list.append(ConvNet.state_dict()[param_tensor])

"""**Determine the number of times that we will need to sample to_plot_storage to form the Inverse CDF to be sampled**"""

height_to_plot=batchsize*FC_intermed_size
width_to_plot=Height_before_FC*Width_before_FC*Conv_L2_channels
depth_to_plot=Conv_L1_channels

print("height of difference distribution volume:"+" "+str(height_to_plot))
print("width of difference distribution volume:"+" "+str(width_to_plot))
print("depth of difference distribution volume:"+" "+str(depth_to_plot))

"""**Sample from Given Error Distribution (to_plot) to form the Inverse CDF**"""

mat_path='/content/drive/My Drive/distribution_data.mat'
storage = loadmat(mat_path)
storage = storage['dd']
to_plot_storage = storage.flatten()

#num_repeats=batchsize*Conv_L2_channels*FC_intermed_size*Height_before_FC*Width_before_FC//len(to_plot_storage)
num_repeats=height_to_plot*width_to_plot*depth_to_plot//len(to_plot_storage)
print(num_repeats)

if draw_errors==True:
  print("drawing elements from NETCAST difference distribution")
### PERTURBATIONS ON...  # NOTE: This code block generates the needed error matrix size automatically (to match the network size specified).
  if num_repeats>1: 
    print("drawing"+" "+str(num_repeats)+" "+"copies from the given difference distribution to form the inverse cdf")
    cdf_inv=Inverse_CDF_to_sample(to_plot_storage,len(to_plot_storage)*num_repeats)
  #to_plot=to_plot_storage
#    to_plot=np.reshape(to_plot,(height_to_plot,width_to_plot,depth_to_plot))
  else:
    cdf_inv=Inverse_CDF_to_sample(to_plot_storage,len(to_plot_storage)*1)
 #   to_plot=np.reshape(to_plot,(-1,width_to_plot,depth_to_plot))

  save_path='/content/drive/My Drive/3D_diffvol.pt'
  Vol=torch.load(save_path).numpy()
  CONV_Diff_Vol=np.reshape(Vol,(72,2*256000,20))
  FC_Diff_Vol=np.reshape(CONV_Diff_Vol,(2880,256*1000))
  
  

else:
# PERTURBATIONS OFF...
  print("drawing a difference distribution of all zeros")
  CONV_Diff_Vol = np.zeros((72,2*256000,20))    #(len(to_plot_storage)*num_repeats) #[height_to_plot,width_to_plot,depth_to_plot])
  FC_Diff_Vol=np.reshape(CONV_Diff_Vol,(2880,256*1000)) 




#save_path='/content/drive/My Drive/3D_diffvol.pt'
#diff_vol=torch.tensor(randm_3Dmat(cdf_inv,height_to_plot, width_to_plot, 20))
#torch.save(diff_vol,save_path)

print(FC_Diff_Vol.shape)
print(CONV_Diff_Vol.shape)

print("max error element"+" "+str(np.max(CONV_Diff_Vol)))

x_samp=torch.randn([1,3,6,6]).numpy()
w=torch.randn([12,3,3,3]).numpy()
net=nn.Conv2d(x_samp.shape[1],w.shape[0],kernel_size=(w.shape[2],w.shape[3]),padding=4,stride=1, dilation=2, bias=False)
with torch.no_grad():
  net.weight=torch.nn.Parameter(torch.from_numpy(w))

output=ADV_Conv_4D_With_Processing(CONV_Diff_Vol,x_samp,w,s=1,h_padding=4,w_padding=4,d_h=2,d_w=2)
gt=net(torch.tensor(x_samp)).detach().numpy()

print(np.average(output-gt))

"""**Plot Histogram of Difference Distribution Being Drawn from**"""

def show_error_hist():
  '''
  This function plots the given error distribution from NETCAST:"to_plot_storage"
  ...along with the error distribution used for actual perturbations- to_plot" that are drawn from the inverse cdf

  NOTE: only makes sense to run this function if perturbations are on, otherwise, it will return a histogram that looks like a spike at 0
  '''

  to_plot_fc1_from_inv_cdf=randm_3Dmat(cdf_inv,1,36864,20).flatten()
  cdf_mean_fc1=np.mean(to_plot_fc1_from_inv_cdf)

  
  original_mean=np.mean(to_plot_storage)
 # ######################################
  plt.figure(figsize=(5,5))
  plt.title("original error dist.")
  _, _,_=plt.hist(to_plot_storage, bins=int(len(to_plot_storage)/10), density=True)

  plt.figure(figsize=(5,5))
#  plt.title("sampled FC1 error dist. via inverse cdf")
#  _, _,_ =plt.hist(to_plot_fc1, bins=int(len(to_plot_fc1)/10), density=True)
  plt.title("sampled FC1 error dist. via volume")
  _, _,_ =plt.hist(to_plot_fc1_from_inv_cdf, bins=int(len(to_plot_fc1_from_inv_cdf)/10), density=True)

  print("===========================")
  print("original distribution mean:"+" "+str(original_mean))
  print("original distribution range:"+" "+str(np.min(to_plot_storage))+" "+"to"+" "+str(np.max(to_plot_storage)))
  print("===========================")
  print("===========================")
  print("FC1 distribution (inverse cdf).....")
  print("mean:"+" "+str(cdf_mean_fc1))
  print("range:"+" "+str(np.min(to_plot_fc1_from_inv_cdf))+" "+"to"+" "+str(np.max(to_plot_fc1_from_inv_cdf)))
  print("===========================")




show_error_hist()

"""**Validate the Custom Convolution Function (which draws from the difference distribution to_plot)**"""

def test_Conv4d_with_processing(max_validation_counter,iterations,s_min,s_max):
  processing_Conv_lst=[]
  for itr in trange(iterations):
    val_c=0
    for validation_input, _ in test_loader:
      val_c+=1
      if val_c>max_validation_counter:
        break
      print("input shape:"+" "+str(validation_input.size()))
      # downsample
      w=torch.ones([1,1,2,2])
      Downsampling_Convolution=nn.Conv2d(validation_input.size()[1],w.size()[0],kernel_size=(w.size()[2],w.size()[2]),padding=0,stride=2,bias=False)
      with torch.no_grad():
         Downsampling_Convolution.weight=torch.nn.Parameter(w)
      x=Downsampling_Convolution(validation_input).detach().numpy()
      print("down-sampled input shape:"+" "+str(x.shape))
#      print(x.shape)
      s=np.random.randint(s_min, s_max)
      w=Kernel_list[0].numpy()
#    print("initial input shape:"+" "+ str(x.shape))
#    print("initial weight shape"+" "+ str(w.shape))
#    print("stride:"+" "+str(s))
#      x=Pad_4D(x, w.shape[2], w.shape[3], s)[0].numpy()
#      print(w.shape)
    # note that the same padded input is put into both the Conv_4D as well as the g_t network 
   
      Post_Processed = ADV_Conv_4D_With_Processing(CONV_Diff_Vol,x,w,s,1,1,1,1)  #Conv_4D_With_Processing_Layer2(cdf_inv,x,w,s)  #Conv4d_with_3d_diff_dist(CONV_Diff_Vol,x,w,s)     
#    print(Post_Processed.shape)
      net=nn.Conv2d(x.shape[1],w.shape[0],kernel_size=(w.shape[2],w.shape[3]),padding=1,stride=s,bias=False)
      with torch.no_grad():
        net.weight=torch.nn.Parameter(torch.from_numpy(w))
    
      G_T=net(torch.from_numpy(x)).detach().numpy()
      processing_Conv_lst.append(np.average(Post_Processed-G_T))

  return np.average(processing_Conv_lst)


max_validation_counter=1
iterations=1
s_min=1
s_max=2


print(test_Conv4d_with_processing(max_validation_counter,iterations,s_min,s_max))
print()
print("NOTE: CONV_4D TEST MUST BE DONE WITH PERTURBATIONS OFF!, otherwise, the error seen will be high")

"""**Validate Custom Matrix Multiplication Function** """

def test_Conv4d_with_processing(iters):
  processing_Matmul_lst=[]
  for iteration in trange(iters):
    x=nn.ReLU()(torch.randn([10,28*28])).numpy()
      #x=np.reshape(x,[50,28*28])
    w=torch.randn([5,28*28]).numpy()

    #############################################################
    n_x=np.max(x)
    c=np.min(w)
    d=np.max(w)
    n_w=max(np.abs(c),np.abs(d))
    x_p = x/n_x
    w_p = w/n_w
    w_pos, w_neg = quick_split_W3D(w_p)
    Prod_plus=Matmul_with_2d_diffdist_elements(FC_Diff_Vol,x_p,w_pos) 
    Prod_minus=Matmul_with_2d_diffdist_elements(FC_Diff_Vol,x_p,w_neg)
    Post_Processed = n_x*n_w*(Prod_plus- Prod_minus) 
      #############################################################
      #Conv_4D_With_Processing_Layer2(cdf_inv,x,w,s)  #Conv4d_with_3d_diff_dist(CONV_Diff_Vol,x,w,s)     
#    print(Post_Processed.shape)
    net= nn.Linear(5,28*28, bias=False)   #nn.Conv2d(x.shape[1],w.shape[0],kernel_size=(w.shape[2],w.shape[3]),padding=1,stride=s,bias=False)
    with torch.no_grad():
      net.weight=torch.nn.Parameter(torch.from_numpy(w))
    
    G_T=net(torch.from_numpy(x)).detach().numpy()
    processing_Matmul_lst.append(np.average(Post_Processed-G_T))

  return np.average(processing_Matmul_lst)


iters=10
matmul_test=test_Conv4d_with_processing(iters)
print(matmul_test)
print("If draw_errors=True, the error below will be large. To validate the custom matrix multiplication function, set draw_error=false")

def ConvNet_With_Difference_Distribution_Errors(input_batch):
  W1=Kernel_list[0].numpy()
  W2=Kernel_list[1].numpy()
  W3=Kernel_list[2].numpy()
  W4=Kernel_list[3].numpy()
  ############################
  x=input_batch.numpy()
  C1 = ADV_Conv_4D_With_Processing(CONV_Diff_Vol,x,W1,global_stride,1,1,1,1)   #Conv_4D_With_Processing_Layer2(cdf_inv,x,W1,global_stride)
  C1=torch.tensor(C1)
  R1=nn.ReLU(inplace=True)(C1).detach().numpy()
  #Padded_x=Pad_4D(R1.detach().numpy(),Conv_weight2_height,Conv_weight2_width, global_stride)[0]
  C2 = ADV_Conv_4D_With_Processing(CONV_Diff_Vol,R1,W2,global_stride,1,1,1,1)  #Conv_4D_With_Processing_Layer2(cdf_inv,Padded_x.detach().numpy(),W2,global_stride)     
  C2=torch.tensor(C2)
  R2=nn.ReLU(inplace=True)(C2).detach().numpy()
  # drop-out is not used in inference
  Flattened_x=np.reshape(R2,(batchsize,R2.shape[1]*R2.shape[2]*R2.shape[3]))

  ###################################################
  n_x1=np.max(Flattened_x)
  c1=np.min(W3)
  d1=np.max(W3)
  n_w1=max(np.abs(c1),np.abs(d1))
  x_p1 = Flattened_x/n_x1
  w_p1 = W3/n_w1
  w_pos1, w_neg1 = quick_split_W3D(w_p1)
#  print([np.min(x_p1),np.max(x_p1)])
#  print([np.min(w_pos1),np.max(w_pos1)])
  Prod_plus1=Matmul_with_2d_diffdist_elements(FC_Diff_Vol,x_p1,w_pos1) 
  Prod_minus1=Matmul_with_2d_diffdist_elements(FC_Diff_Vol,x_p1,w_neg1)
  Post_Processed1 = n_x1*n_w1*(Prod_plus1- Prod_minus1) 
  FC1=torch.tensor(Post_Processed1)
  ###################################################
  R3=nn.ReLU(inplace=True)(FC1).detach().numpy()
  ####################################################
  n_x2=np.max(R3)
  c2=np.min(W4)
  d2=np.max(W4)
  n_w2=max(np.abs(c2),np.abs(d2))
  x_p2 = R3/n_x2
  w_p2 = W4/n_w2
  w_pos2, w_neg2 = quick_split_W3D(w_p2)
#  print([np.min(x_p2),np.max(x_p2)])
#  print([np.min(w_pos2),np.max(w_pos2)])
  Prod_plus2=Matmul_with_2d_diffdist_elements(FC_Diff_Vol,x_p2,w_pos2) 
  Prod_minus2=Matmul_with_2d_diffdist_elements(FC_Diff_Vol,x_p2,w_neg2)
  Post_Processed2 = n_x2*n_w2*(Prod_plus2- Prod_minus2) 
  FC2=torch.tensor(Post_Processed2)
  ####################################################
  Final_output=nn.Softmax()(FC2)
  print("final output is of size..."+str(Final_output.shape))
  print()
  return torch.tensor(Final_output)

"""**Propagate Error through the ConvNet**"""

model_with_propagated_error = ConvNet_With_Difference_Distribution_Errors   # ConvNet_With_Volume_Errors  #
avg_propagated_acc, propagated_acc_lst = test_CONV_model(model_with_propagated_error)